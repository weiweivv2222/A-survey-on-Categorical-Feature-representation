{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb11203-5deb-43da-9602-6c0682ddf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add confident interval\n",
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "from scipy import stats\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load and preprocess data\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "bank_data = pd.read_csv(data_path+'adult.csv', sep=',')\n",
    "\n",
    "df_bank, cat_cols = adult_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "y = df_bank.y\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "# We will determine the number_of_features inside the cross-validation loop after preprocessing\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss', random_state=seed)),\n",
    "    # ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(\n",
    "        model=create_network,\n",
    "        epochs=100, batch_size=100, verbose=0, random_state=seed))\n",
    "]\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)\n",
    "\n",
    "# Function to calculate confidence intervals\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, m - h, m + h\n",
    "\n",
    "# Loop over models\n",
    "for name, model in models:\n",
    "    print(f\"Classifier: {name}\")\n",
    "    # Lists to store metrics for each fold\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    \n",
    "    # Start the timer before cross-validation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Preprocess data within the fold\n",
    "        # One-hot encoding\n",
    "        import category_encoders as ce\n",
    "        one_hot_encoder = ce.OneHotEncoder(cols=cat_cols)\n",
    "        X_train_ohe = one_hot_encoder.fit_transform(X_train_fold)\n",
    "        X_test_ohe = one_hot_encoder.transform(X_test_fold)\n",
    "        \n",
    "        # Standard scaling\n",
    "        stc = StandardScaler()\n",
    "        X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "        X_test_scaled = stc.transform(X_test_ohe)\n",
    "        \n",
    "        # Update number_of_features for MLP\n",
    "        number_of_features = X_train_scaled.shape[1]\n",
    "        if name == 'MLP':\n",
    "            # Update the model with the correct number of features\n",
    "            model.set_params(model__number_of_features=number_of_features)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train_fold)\n",
    "        # Predict on the test fold\n",
    "        y_pred_fold = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Get prediction probabilities for ROC AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_prob_fold = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            # For classifiers without predict_proba, use decision_function\n",
    "            print(\"not having proba\")\n",
    "            y_pred_prob_fold = model.decision_function(X_test_scaled)\n",
    "            # Normalize the decision function output to [0,1] range\n",
    "            y_pred_prob_fold = (y_pred_prob_fold - y_pred_prob_fold.min()) / (y_pred_prob_fold.max() - y_pred_prob_fold.min())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracies.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "        precisions.append(precision_score(y_test_fold, y_pred_fold, zero_division=0))\n",
    "        recalls.append(recall_score(y_test_fold, y_pred_fold))\n",
    "        f1s.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        roc_aucs.append(roc_auc_score(y_test_fold, y_pred_prob_fold))\n",
    "        \n",
    "       # print(f\"Fold {fold} completed.\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Stop the timer after cross-validation\n",
    "    end_time = time.time()\n",
    "    total_computation_time = end_time - start_time  # Total time for the model\n",
    "    \n",
    "    # Calculate mean and confidence intervals\n",
    "    acc_mean, acc_ci_lower, acc_ci_upper = confidence_interval(accuracies)\n",
    "    prec_mean, prec_ci_lower, prec_ci_upper = confidence_interval(precisions)\n",
    "    rec_mean, rec_ci_lower, rec_ci_upper = confidence_interval(recalls)\n",
    "    f1_mean, f1_ci_lower, f1_ci_upper = confidence_interval(f1s)\n",
    "    roc_mean, roc_ci_lower, roc_ci_upper = confidence_interval(roc_aucs)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {acc_mean:.3f} (95% CI: {acc_ci_lower:.3f} - {acc_ci_upper:.3f})\")\n",
    "    print(f\"Precision: {prec_mean:.3f} (95% CI: {prec_ci_lower:.3f} - {prec_ci_upper:.3f})\")\n",
    "    print(f\"Recall: {rec_mean:.3f} (95% CI: {rec_ci_lower:.3f} - {rec_ci_upper:.3f})\")\n",
    "    print(f\"F1 Score: {f1_mean:.3f} (95% CI: {f1_ci_lower:.3f} - {f1_ci_upper:.3f})\")\n",
    "    print(f\"ROC AUC: {roc_mean:.3f} (95% CI: {roc_ci_lower:.3f} - {roc_ci_upper:.3f})\")\n",
    "    print(f\"Total Computation Time: {total_computation_time:.3f} seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058034cb-39ae-4769-a7f4-44ed86fe30f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "Accuracy: 0.849 (95% CI: 0.846 - 0.851)\n",
      "Precision: 0.736 (95% CI: 0.729 - 0.743)\n",
      "Recall: 0.606 (95% CI: 0.597 - 0.616)\n",
      "F1 Score: 0.665 (95% CI: 0.658 - 0.672)\n",
      "ROC AUC: 0.905 (95% CI: 0.901 - 0.908)\n",
      "Total Computation Time: 27.194 seconds\n",
      "\n",
      "Classifier: DT\n",
      "Accuracy: 0.815 (95% CI: 0.812 - 0.817)\n",
      "Precision: 0.940 (95% CI: 0.934 - 0.946)\n",
      "Recall: 0.269 (95% CI: 0.260 - 0.279)\n",
      "F1 Score: 0.418 (95% CI: 0.406 - 0.430)\n",
      "ROC AUC: 0.832 (95% CI: 0.829 - 0.836)\n",
      "Total Computation Time: 29.393 seconds\n",
      "\n",
      "Classifier: RF\n",
      "Accuracy: 0.824 (95% CI: 0.822 - 0.827)\n",
      "Precision: 0.886 (95% CI: 0.875 - 0.897)\n",
      "Recall: 0.335 (95% CI: 0.324 - 0.345)\n",
      "F1 Score: 0.485 (95% CI: 0.474 - 0.496)\n",
      "ROC AUC: 0.894 (95% CI: 0.890 - 0.898)\n",
      "Total Computation Time: 119.732 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "Accuracy: 0.813 (95% CI: 0.809 - 0.816)\n",
      "Precision: 0.634 (95% CI: 0.626 - 0.643)\n",
      "Recall: 0.576 (95% CI: 0.565 - 0.588)\n",
      "F1 Score: 0.604 (95% CI: 0.595 - 0.613)\n",
      "ROC AUC: 0.811 (95% CI: 0.805 - 0.818)\n",
      "Total Computation Time: 58.492 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "Accuracy: 0.870 (95% CI: 0.866 - 0.874)\n",
      "Precision: 0.783 (95% CI: 0.773 - 0.793)\n",
      "Recall: 0.660 (95% CI: 0.648 - 0.671)\n",
      "F1 Score: 0.716 (95% CI: 0.707 - 0.725)\n",
      "ROC AUC: 0.928 (95% CI: 0.925 - 0.931)\n",
      "Total Computation Time: 53.782 seconds\n",
      "\n",
      "Classifier: MLP\n",
      "Accuracy: 0.842 (95% CI: 0.838 - 0.845)\n",
      "Precision: 0.713 (95% CI: 0.700 - 0.725)\n",
      "Recall: 0.610 (95% CI: 0.593 - 0.626)\n",
      "F1 Score: 0.656 (95% CI: 0.647 - 0.665)\n",
      "ROC AUC: 0.894 (95% CI: 0.891 - 0.898)\n",
      "Total Computation Time: 1455.523 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add confident interval\n",
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "from scipy import stats\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load and preprocess data\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "bank_data = pd.read_csv(data_path+'adult.csv', sep=',')\n",
    "\n",
    "df_bank, cat_cols = adult_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "y = df_bank.y\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "# We will determine the number_of_features inside the cross-validation loop after preprocessing\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss', random_state=seed)),\n",
    "    # ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(\n",
    "        model=create_network,\n",
    "        epochs=100, batch_size=100, verbose=0, random_state=seed))\n",
    "]\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)\n",
    "\n",
    "# Function to calculate confidence intervals\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, m - h, m + h\n",
    "\n",
    "# Loop over models\n",
    "for name, model in models:\n",
    "    print(f\"Classifier: {name}\")\n",
    "    # Lists to store metrics for each fold\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    \n",
    "    # Start the timer before cross-validation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Preprocess data within the fold\n",
    "        # One-hot encoding\n",
    "        import category_encoders as ce\n",
    "        one_hot_encoder = ce.OneHotEncoder(cols=cat_cols)\n",
    "        X_train_ohe = one_hot_encoder.fit_transform(X_train_fold)\n",
    "        X_test_ohe = one_hot_encoder.transform(X_test_fold)\n",
    "        \n",
    "        # Standard scaling\n",
    "        stc = StandardScaler()\n",
    "        X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "        X_test_scaled = stc.transform(X_test_ohe)\n",
    "        \n",
    "        # Update number_of_features for MLP\n",
    "        number_of_features = X_train_scaled.shape[1]\n",
    "        if name == 'MLP':\n",
    "            # Update the model with the correct number of features\n",
    "            model.set_params(model__number_of_features=number_of_features)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train_fold)\n",
    "        # Predict on the test fold\n",
    "        y_pred_fold = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Get prediction probabilities for ROC AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_prob_fold = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            # For classifiers without predict_proba, use decision_function\n",
    "            print(\"not having proba\")\n",
    "            y_pred_prob_fold = model.decision_function(X_test_scaled)\n",
    "            # Normalize the decision function output to [0,1] range\n",
    "            y_pred_prob_fold = (y_pred_prob_fold - y_pred_prob_fold.min()) / (y_pred_prob_fold.max() - y_pred_prob_fold.min())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracies.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "        precisions.append(precision_score(y_test_fold, y_pred_fold, zero_division=0))\n",
    "        recalls.append(recall_score(y_test_fold, y_pred_fold))\n",
    "        f1s.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        roc_aucs.append(roc_auc_score(y_test_fold, y_pred_prob_fold))\n",
    "        \n",
    "       # print(f\"Fold {fold} completed.\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Stop the timer after cross-validation\n",
    "    end_time = time.time()\n",
    "    total_computation_time = end_time - start_time  # Total time for the model\n",
    "    \n",
    "    # Calculate mean and confidence intervals\n",
    "    acc_mean, acc_ci_lower, acc_ci_upper = confidence_interval(accuracies)\n",
    "    prec_mean, prec_ci_lower, prec_ci_upper = confidence_interval(precisions)\n",
    "    rec_mean, rec_ci_lower, rec_ci_upper = confidence_interval(recalls)\n",
    "    f1_mean, f1_ci_lower, f1_ci_upper = confidence_interval(f1s)\n",
    "    roc_mean, roc_ci_lower, roc_ci_upper = confidence_interval(roc_aucs)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {acc_mean:.3f} (95% CI: {acc_ci_lower:.3f} - {acc_ci_upper:.3f})\")\n",
    "    print(f\"Precision: {prec_mean:.3f} (95% CI: {prec_ci_lower:.3f} - {prec_ci_upper:.3f})\")\n",
    "    print(f\"Recall: {rec_mean:.3f} (95% CI: {rec_ci_lower:.3f} - {rec_ci_upper:.3f})\")\n",
    "    print(f\"F1 Score: {f1_mean:.3f} (95% CI: {f1_ci_lower:.3f} - {f1_ci_upper:.3f})\")\n",
    "    print(f\"ROC AUC: {roc_mean:.3f} (95% CI: {roc_ci_lower:.3f} - {roc_ci_upper:.3f})\")\n",
    "    print(f\"Total Computation Time: {total_computation_time:.3f} seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb70532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "[[6282  536]\n",
      " [ 887 1340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.876     0.921     0.898      6818\n",
      "           1      0.714     0.602     0.653      2227\n",
      "\n",
      "    accuracy                          0.843      9045\n",
      "   macro avg      0.795     0.762     0.776      9045\n",
      "weighted avg      0.836     0.843     0.838      9045\n",
      "\n",
      "ROC AUC Score: 0.899\n",
      "Computation Time: 0.157 seconds\n",
      "\n",
      "Classifier: DT\n",
      "[[6773   45]\n",
      " [1635  592]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.806     0.993     0.890      6818\n",
      "           1      0.929     0.266     0.413      2227\n",
      "\n",
      "    accuracy                          0.814      9045\n",
      "   macro avg      0.867     0.630     0.652      9045\n",
      "weighted avg      0.836     0.814     0.772      9045\n",
      "\n",
      "ROC AUC Score: 0.825\n",
      "Computation Time: 0.119 seconds\n",
      "\n",
      "Classifier: RF\n",
      "[[6700  118]\n",
      " [1477  750]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.819     0.983     0.894      6818\n",
      "           1      0.864     0.337     0.485      2227\n",
      "\n",
      "    accuracy                          0.824      9045\n",
      "   macro avg      0.842     0.660     0.689      9045\n",
      "weighted avg      0.830     0.824     0.793      9045\n",
      "\n",
      "ROC AUC Score: 0.888\n",
      "Computation Time: 2.782 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "[[6029  789]\n",
      " [ 962 1265]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.862     0.884     0.873      6818\n",
      "           1      0.616     0.568     0.591      2227\n",
      "\n",
      "    accuracy                          0.806      9045\n",
      "   macro avg      0.739     0.726     0.732      9045\n",
      "weighted avg      0.802     0.806     0.804      9045\n",
      "\n",
      "ROC AUC Score: 0.806\n",
      "Computation Time: 2.936 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "[[6379  439]\n",
      " [ 755 1472]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.894     0.936     0.914      6818\n",
      "           1      0.770     0.661     0.711      2227\n",
      "\n",
      "    accuracy                          0.868      9045\n",
      "   macro avg      0.832     0.798     0.813      9045\n",
      "weighted avg      0.864     0.868     0.864      9045\n",
      "\n",
      "ROC AUC Score: 0.926\n",
      "Computation Time: 0.568 seconds\n",
      "\n",
      "Classifier: SVM\n",
      "[[6326  492]\n",
      " [ 919 1308]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.873     0.928     0.900      6818\n",
      "           1      0.727     0.587     0.650      2227\n",
      "\n",
      "    accuracy                          0.844      9045\n",
      "   macro avg      0.800     0.758     0.775      9045\n",
      "weighted avg      0.837     0.844     0.838      9045\n",
      "\n",
      "ROC AUC Score: 0.892\n",
      "Computation Time: 1165.490 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MLP\n",
      "[[6172  646]\n",
      " [ 857 1370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.878     0.905     0.891      6818\n",
      "           1      0.680     0.615     0.646      2227\n",
      "\n",
      "    accuracy                          0.834      9045\n",
      "   macro avg      0.779     0.760     0.769      9045\n",
      "weighted avg      0.829     0.834     0.831      9045\n",
      "\n",
      "ROC AUC Score: 0.884\n",
      "Computation Time: 47.736 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "data_path_out = config_cat_embedding.paths['data_output']\n",
    "bank_data = pd.read_csv(data_path+'adult.csv', sep=',')\n",
    "\n",
    "df_bank, cat_cols = adult_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "target = df_bank.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=1500)\n",
    "\n",
    "# One-hot encoding\n",
    "import category_encoders as ce\n",
    "one_hot_encoder = ce.OneHotEncoder(cols=cat_cols) \n",
    "X_train_ohe = one_hot_encoder.fit_transform(X_train)\n",
    "X_test_ohe = one_hot_encoder.transform(X_test)  # Use transform() instead of fit_transform()\n",
    "\n",
    "# Standard scaling\n",
    "stc = StandardScaler()\n",
    "X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "X_test_scaled = stc.transform(X_test_ohe)\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "number_of_features = X_train_scaled.shape[1]  # Number of features in the input data\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss')),\n",
    "    ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(build_fn=create_network, number_of_features=number_of_features, epochs=100, batch_size=100, verbose=0))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    start_time = time.time()  # Start time\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_prob = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    end_time = time.time()  # End time\n",
    "    computation_time = end_time - start_time  # Computation time\n",
    "    \n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, digits=3))  # Set digits to 3 for three decimal places\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_prob[:, 1]):.3f}\")\n",
    "    print(f\"Computation Time: {computation_time:.3f} seconds\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c9fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xg16060\\AppData\\Local\\Temp\\1\\ipykernel_25232\\1248371534.py:59: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  ('MLP', KerasClassifier(build_fn=create_network, number_of_features=number_of_features, epochs=100, batch_size=100, verbose=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "[[7126  168]\n",
      " [ 619  325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.920     0.977     0.948      7294\n",
      "           1      0.659     0.344     0.452       944\n",
      "\n",
      "    accuracy                          0.904      8238\n",
      "   macro avg      0.790     0.661     0.700      8238\n",
      "weighted avg      0.890     0.904     0.891      8238\n",
      "\n",
      "ROC AUC Score: 0.917\n",
      "Computation Time: 0.068 seconds\n",
      "\n",
      "Classifier: DT\n",
      "[[7106  188]\n",
      " [ 618  326]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.920     0.974     0.946      7294\n",
      "           1      0.634     0.345     0.447       944\n",
      "\n",
      "    accuracy                          0.902      8238\n",
      "   macro avg      0.777     0.660     0.697      8238\n",
      "weighted avg      0.887     0.902     0.889      8238\n",
      "\n",
      "ROC AUC Score: 0.839\n",
      "Computation Time: 0.042 seconds\n",
      "\n",
      "Classifier: RF\n",
      "[[7246   48]\n",
      " [ 771  173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.904     0.993     0.947      7294\n",
      "           1      0.783     0.183     0.297       944\n",
      "\n",
      "    accuracy                          0.901      8238\n",
      "   macro avg      0.843     0.588     0.622      8238\n",
      "weighted avg      0.890     0.901     0.872      8238\n",
      "\n",
      "ROC AUC Score: 0.914\n",
      "Computation Time: 1.852 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "[[7032  262]\n",
      " [ 650  294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.915     0.964     0.939      7294\n",
      "           1      0.529     0.311     0.392       944\n",
      "\n",
      "    accuracy                          0.889      8238\n",
      "   macro avg      0.722     0.638     0.666      8238\n",
      "weighted avg      0.871     0.889     0.876      8238\n",
      "\n",
      "ROC AUC Score: 0.741\n",
      "Computation Time: 1.488 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "[[7032  262]\n",
      " [ 492  452]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.935     0.964     0.949      7294\n",
      "           1      0.633     0.479     0.545       944\n",
      "\n",
      "    accuracy                          0.908      8238\n",
      "   macro avg      0.784     0.721     0.747      8238\n",
      "weighted avg      0.900     0.908     0.903      8238\n",
      "\n",
      "ROC AUC Score: 0.932\n",
      "Computation Time: 0.899 seconds\n",
      "\n",
      "Classifier: SVM\n",
      "[[7139  155]\n",
      " [ 650  294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.917     0.979     0.947      7294\n",
      "           1      0.655     0.311     0.422       944\n",
      "\n",
      "    accuracy                          0.902      8238\n",
      "   macro avg      0.786     0.645     0.684      8238\n",
      "weighted avg      0.887     0.902     0.887      8238\n",
      "\n",
      "ROC AUC Score: 0.914\n",
      "Computation Time: 98.686 seconds\n",
      "\n",
      "258/258 [==============================] - 0s 588us/step\n",
      "258/258 [==============================] - 0s 547us/step\n",
      "Classifier: MLP\n",
      "[[6887  407]\n",
      " [ 491  453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.933     0.944     0.939      7294\n",
      "           1      0.527     0.480     0.502       944\n",
      "\n",
      "    accuracy                          0.891      8238\n",
      "   macro avg      0.730     0.712     0.721      8238\n",
      "weighted avg      0.887     0.891     0.889      8238\n",
      "\n",
      "ROC AUC Score: 0.894\n",
      "Computation Time: 27.441 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "data_path_out = config_cat_embedding.paths['data_output']\n",
    "bank_data = pd.read_csv(data_path+'adult.csv', sep=',')\n",
    "\n",
    "df_bank, cat_cols = adult_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "target = df_bank.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=1500)\n",
    "\n",
    "# One-hot encoding\n",
    "import category_encoders as ce\n",
    "one_hot_encoder = ce.OneHotEncoder(cols=cat_cols) \n",
    "X_train_ohe = one_hot_encoder.fit_transform(X_train)\n",
    "X_test_ohe = one_hot_encoder.transform(X_test)  # Use transform() instead of fit_transform()\n",
    "\n",
    "# Standard scaling\n",
    "stc = StandardScaler()\n",
    "X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "X_test_scaled = stc.transform(X_test_ohe)\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "number_of_features = X_train_scaled.shape[1]  # Number of features in the input data\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss')),\n",
    "    ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(build_fn=create_network, number_of_features=number_of_features, epochs=100, batch_size=100, verbose=0))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    start_time = time.time()  # Start time\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_prob = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    end_time = time.time()  # End time\n",
    "    computation_time = end_time - start_time  # Computation time\n",
    "    \n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, digits=3))  # Set digits to 3 for three decimal places\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_prob[:, 1]):.3f}\")\n",
    "    print(f\"Computation Time: {computation_time:.3f} seconds\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6774535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xg16060\\AppData\\Local\\Temp\\1\\ipykernel_29636\\2582821143.py:59: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  ('MLP', KerasClassifier(build_fn=create_network, number_of_features=number_of_features, epochs=100, batch_size=100, verbose=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "[[6281  537]\n",
      " [ 889 1338]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8760    0.9212    0.8981      6818\n",
      "     class 1     0.7136    0.6008    0.6524      2227\n",
      "\n",
      "    accuracy                         0.8423      9045\n",
      "   macro avg     0.7948    0.7610    0.7752      9045\n",
      "weighted avg     0.8360    0.8423    0.8376      9045\n",
      "\n",
      "ROC AUC Score: 0.899\n",
      "Computation Time: 0.314 seconds\n",
      "\n",
      "Classifier: DT\n",
      "[[6773   45]\n",
      " [1635  592]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8055    0.9934    0.8897      6818\n",
      "     class 1     0.9294    0.2658    0.4134      2227\n",
      "\n",
      "    accuracy                         0.8143      9045\n",
      "   macro avg     0.8674    0.6296    0.6515      9045\n",
      "weighted avg     0.8360    0.8143    0.7724      9045\n",
      "\n",
      "ROC AUC Score: 0.825\n",
      "Computation Time: 0.069 seconds\n",
      "\n",
      "Classifier: RF\n",
      "[[6700  118]\n",
      " [1477  750]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8194    0.9827    0.8936      6818\n",
      "     class 1     0.8641    0.3368    0.4847      2227\n",
      "\n",
      "    accuracy                         0.8237      9045\n",
      "   macro avg     0.8417    0.6597    0.6891      9045\n",
      "weighted avg     0.8304    0.8237    0.7929      9045\n",
      "\n",
      "ROC AUC Score: 0.888\n",
      "Computation Time: 2.078 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "[[6029  789]\n",
      " [ 962 1265]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8624    0.8843    0.8732      6818\n",
      "     class 1     0.6159    0.5680    0.5910      2227\n",
      "\n",
      "    accuracy                         0.8064      9045\n",
      "   macro avg     0.7391    0.7262    0.7321      9045\n",
      "weighted avg     0.8017    0.8064    0.8037      9045\n",
      "\n",
      "ROC AUC Score: 0.806\n",
      "Computation Time: 2.029 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "[[6370  448]\n",
      " [ 755 1472]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8940    0.9343    0.9137      6818\n",
      "     class 1     0.7667    0.6610    0.7099      2227\n",
      "\n",
      "    accuracy                         0.8670      9045\n",
      "   macro avg     0.8304    0.7976    0.8118      9045\n",
      "weighted avg     0.8627    0.8670    0.8635      9045\n",
      "\n",
      "ROC AUC Score: 0.926\n",
      "Computation Time: 1.475 seconds\n",
      "\n",
      "Classifier: SVM\n",
      "[[6326  492]\n",
      " [ 919 1308]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8732    0.9278    0.8997      6818\n",
      "     class 1     0.7267    0.5873    0.6496      2227\n",
      "\n",
      "    accuracy                         0.8440      9045\n",
      "   macro avg     0.7999    0.7576    0.7746      9045\n",
      "weighted avg     0.8371    0.8440    0.8381      9045\n",
      "\n",
      "ROC AUC Score: 0.892\n",
      "Computation Time: 422.138 seconds\n",
      "\n",
      "283/283 [==============================] - 0s 565us/step\n",
      "283/283 [==============================] - 0s 546us/step\n",
      "Classifier: MLP\n",
      "[[6206  612]\n",
      " [ 856 1371]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8788    0.9102    0.8942      6818\n",
      "     class 1     0.6914    0.6156    0.6513      2227\n",
      "\n",
      "    accuracy                         0.8377      9045\n",
      "   macro avg     0.7851    0.7629    0.7728      9045\n",
      "weighted avg     0.8326    0.8377    0.8344      9045\n",
      "\n",
      "ROC AUC Score: 0.892\n",
      "Computation Time: 29.889 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "data_path_out = config_cat_embedding.paths['data_output']\n",
    "bank_data = pd.read_csv(data_path+'adult.csv', sep=',')\n",
    "\n",
    "df_bank, cat_cols = adult_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "target = df_bank.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=1500)\n",
    "\n",
    "# One-hot encoding\n",
    "import category_encoders as ce\n",
    "one_hot_encoder = ce.OneHotEncoder(cols=cat_cols) \n",
    "X_train_ohe = one_hot_encoder.fit_transform(X_train)\n",
    "X_test_ohe = one_hot_encoder.transform(X_test)  # Use transform() instead of fit_transform()\n",
    "\n",
    "# Standard scaling\n",
    "stc = StandardScaler()\n",
    "X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "X_test_scaled = stc.transform(X_test_ohe)\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "number_of_features = X_train_scaled.shape[1]  # Number of features in the input data\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss')),\n",
    "   ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "   ('MLP', KerasClassifier(build_fn=create_network, number_of_features=number_of_features, epochs=100, batch_size=100, verbose=0))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    start_time = time.time()  # Start time\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_prob = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    end_time = time.time()  # End time\n",
    "    computation_time = end_time - start_time  # Computation time\n",
    "    \n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=['class 0', 'class 1'], digits=4))  # Set digits to 3 for three decimal places\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_prob[:, 1]):.3f}\")\n",
    "    print(f\"Computation Time: {computation_time:.3f} seconds\")\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
