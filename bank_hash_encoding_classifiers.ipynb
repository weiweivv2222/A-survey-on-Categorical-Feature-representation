{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bdba3f4-fd67-4f7d-b6d1-d189166fce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "Accuracy: 0.905 (95% CI: 0.902 - 0.907)\n",
      "Precision: 0.649 (95% CI: 0.631 - 0.667)\n",
      "Recall: 0.330 (95% CI: 0.311 - 0.349)\n",
      "F1 Score: 0.437 (95% CI: 0.417 - 0.456)\n",
      "ROC AUC: 0.883 (95% CI: 0.878 - 0.889)\n",
      "Total Computation Time: 60.075 seconds\n",
      "\n",
      "Classifier: DT\n",
      "Accuracy: 0.906 (95% CI: 0.904 - 0.908)\n",
      "Precision: 0.650 (95% CI: 0.632 - 0.668)\n",
      "Recall: 0.358 (95% CI: 0.342 - 0.374)\n",
      "F1 Score: 0.461 (95% CI: 0.445 - 0.478)\n",
      "ROC AUC: 0.842 (95% CI: 0.835 - 0.849)\n",
      "Total Computation Time: 46.349 seconds\n",
      "\n",
      "Classifier: RF\n",
      "Accuracy: 0.900 (95% CI: 0.898 - 0.902)\n",
      "Precision: 0.764 (95% CI: 0.739 - 0.789)\n",
      "Recall: 0.160 (95% CI: 0.144 - 0.176)\n",
      "F1 Score: 0.263 (95% CI: 0.241 - 0.285)\n",
      "ROC AUC: 0.882 (95% CI: 0.876 - 0.888)\n",
      "Total Computation Time: 121.604 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "Accuracy: 0.890 (95% CI: 0.887 - 0.893)\n",
      "Precision: 0.519 (95% CI: 0.498 - 0.540)\n",
      "Recall: 0.339 (95% CI: 0.319 - 0.359)\n",
      "F1 Score: 0.409 (95% CI: 0.390 - 0.429)\n",
      "ROC AUC: 0.759 (95% CI: 0.749 - 0.768)\n",
      "Total Computation Time: 79.302 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "Accuracy: 0.905 (95% CI: 0.903 - 0.907)\n",
      "Precision: 0.621 (95% CI: 0.606 - 0.636)\n",
      "Recall: 0.398 (95% CI: 0.378 - 0.417)\n",
      "F1 Score: 0.484 (95% CI: 0.466 - 0.502)\n",
      "ROC AUC: 0.899 (95% CI: 0.894 - 0.904)\n",
      "Total Computation Time: 67.321 seconds\n",
      "\n",
      "Classifier: MLP\n",
      "Accuracy: 0.901 (95% CI: 0.898 - 0.904)\n",
      "Precision: 0.598 (95% CI: 0.573 - 0.623)\n",
      "Recall: 0.395 (95% CI: 0.377 - 0.412)\n",
      "F1 Score: 0.473 (95% CI: 0.459 - 0.488)\n",
      "ROC AUC: 0.891 (95% CI: 0.886 - 0.896)\n",
      "Total Computation Time: 1460.618 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add confidence interval\n",
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "from scipy import stats\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load and preprocess data\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "bank_data = pd.read_csv(data_path + 'bank-additional-full.csv', sep=';')\n",
    "\n",
    "df_bank, cat_cols = bank_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "y = df_bank.y\n",
    "\n",
    "# Convert target variable to numeric if necessary\n",
    "# Assuming 'y' contains 'yes'/'no', map them to 1/0\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "# We will determine the number_of_features inside the cross-validation loop after preprocessing\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss', random_state=seed)),\n",
    "    # ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(\n",
    "        model=create_network,\n",
    "        epochs=100, batch_size=100, verbose=0, random_state=seed))\n",
    "]\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)\n",
    "\n",
    "# Function to calculate confidence intervals\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, m - h, m + h\n",
    "\n",
    "# Loop over models\n",
    "for name, model in models:\n",
    "    print(f\"Classifier: {name}\")\n",
    "    # Lists to store metrics for each fold\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    \n",
    "    # Start the timer before cross-validation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Preprocess data within the fold\n",
    "        # Hashing encoding\n",
    "        import category_encoders as ce\n",
    "        n_components = 9  \n",
    "        hashing_encoder = ce.HashingEncoder(cols=cat_cols, n_components=n_components, return_df=True)\n",
    "        X_train_hash = hashing_encoder.fit_transform(X_train_fold, y_train_fold)\n",
    "        X_test_hash = hashing_encoder.transform(X_test_fold)\n",
    "        \n",
    "        # Standard scaling\n",
    "        stc = StandardScaler()\n",
    "        X_train_scaled = stc.fit_transform(X_train_hash)\n",
    "        X_test_scaled = stc.transform(X_test_hash)\n",
    "        \n",
    "        # Update number_of_features for MLP\n",
    "        number_of_features = X_train_scaled.shape[1]\n",
    "        if name == 'MLP':\n",
    "            # Update the model with the correct number of features\n",
    "            model.set_params(model__number_of_features=number_of_features)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train_fold)\n",
    "        # Predict on the test fold\n",
    "        y_pred_fold = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Get prediction probabilities for ROC AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_prob_fold = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            # For classifiers without predict_proba, use decision_function\n",
    "            y_pred_prob_fold = model.decision_function(X_test_scaled)\n",
    "            # Normalize the decision function output to [0,1] range\n",
    "            y_pred_prob_fold = (y_pred_prob_fold - y_pred_prob_fold.min()) / (y_pred_prob_fold.max() - y_pred_prob_fold.min())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracies.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "        precisions.append(precision_score(y_test_fold, y_pred_fold, zero_division=0))\n",
    "        recalls.append(recall_score(y_test_fold, y_pred_fold))\n",
    "        f1s.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        roc_aucs.append(roc_auc_score(y_test_fold, y_pred_prob_fold))\n",
    "        \n",
    "        # print(f\"Fold {fold} completed.\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Stop the timer after cross-validation\n",
    "    end_time = time.time()\n",
    "    total_computation_time = end_time - start_time  # Total time for the model\n",
    "    \n",
    "    # Calculate mean and confidence intervals\n",
    "    acc_mean, acc_ci_lower, acc_ci_upper = confidence_interval(accuracies)\n",
    "    prec_mean, prec_ci_lower, prec_ci_upper = confidence_interval(precisions)\n",
    "    rec_mean, rec_ci_lower, rec_ci_upper = confidence_interval(recalls)\n",
    "    f1_mean, f1_ci_lower, f1_ci_upper = confidence_interval(f1s)\n",
    "    roc_mean, roc_ci_lower, roc_ci_upper = confidence_interval(roc_aucs)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {acc_mean:.3f} (95% CI: {acc_ci_lower:.3f} - {acc_ci_upper:.3f})\")\n",
    "    print(f\"Precision: {prec_mean:.3f} (95% CI: {prec_ci_lower:.3f} - {prec_ci_upper:.3f})\")\n",
    "    print(f\"Recall: {rec_mean:.3f} (95% CI: {rec_ci_lower:.3f} - {rec_ci_upper:.3f})\")\n",
    "    print(f\"F1 Score: {f1_mean:.3f} (95% CI: {f1_ci_lower:.3f} - {f1_ci_upper:.3f})\")\n",
    "    print(f\"ROC AUC: {roc_mean:.3f} (95% CI: {roc_ci_lower:.3f} - {roc_ci_upper:.3f})\")\n",
    "    print(f\"Total Computation Time: {total_computation_time:.3f} seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59254719-7c3f-4bfb-a22d-7270c8d577d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import logging\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a8acf2-c2a3-4f36-9763-0831da1e54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import logging\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "data_path_out = config_cat_embedding.paths['data_output']\n",
    "bank_data = pd.read_csv(data_path + 'bank-additional-full.csv', sep=';')\n",
    "\n",
    "df_bank, cat_cols = bank_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "target = df_bank.y\n",
    "\n",
    "# Define number of runs for repeated train-test splits\n",
    "n_runs = 5\n",
    "seed = 42\n",
    "\n",
    "# One-hot encoding\n",
    "import category_encoders as ce\n",
    "hash_encoder = ce.HashingEncoder(cols=cat_cols, n_components=2)#9\n",
    "\n",
    "# Standard scaling\n",
    "stc = StandardScaler()\n",
    "\n",
    "# Define the classifiers\n",
    "number_of_features = X.shape[1]\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed))\n",
    "   # ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    #('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    #('XGB', XGBClassifier(eval_metric='logloss', use_label_encoder=False)),\n",
    "    #('SVM', SVC(kernel='linear', random_state=seed, probability=True))\n",
    "   # ('MLP', KerasClassifier(build_fn=lambda: create_network(number_of_features), epochs=100, batch_size=100, verbose=0))\n",
    "]\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate the models multiple times\n",
    "for name, model in models:\n",
    "    logging.info(f\"Classifier: {name}\")\n",
    "    print(f\"Classifier: {name}\")\n",
    "    # Lists to store metrics for each run\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    roc_auc_scores = []\n",
    "    computation_times = []\n",
    "    \n",
    "    # Repeat train-test split n_runs times\n",
    "    for run in range(n_runs):\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=seed + run)\n",
    "        \n",
    "        # One-hot encoding on the training and test data\n",
    "        X_train_ohe = hash_encoder.fit_transform(X_train)\n",
    "        X_test_ohe = hash_encoder.transform(X_test)\n",
    "        \n",
    "        # Standard scaling\n",
    "        X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "        X_test_scaled = stc.transform(X_test_ohe)\n",
    "        \n",
    "        # Train the model\n",
    "        start_time = time.time()  # Start time\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        end_time = time.time()  # End time\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Computation time\n",
    "        computation_time = end_time - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        recall_scores.append(recall_score(y_test, y_pred, zero_division=0))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, zero_division=0))\n",
    "        if y_pred_prob is not None:\n",
    "            roc_auc_scores.append(roc_auc_score(y_test, y_pred_prob))\n",
    "        else:\n",
    "            roc_auc_scores.append(None)\n",
    "        computation_times.append(computation_time)\n",
    "    \n",
    "    # Compute mean and standard deviation for all metrics\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    std_accuracy = np.std(accuracy_scores)\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    std_precision = np.std(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    std_recall = np.std(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    std_f1 = np.std(f1_scores)\n",
    "    mean_roc_auc = np.mean([score for score in roc_auc_scores if score is not None]) if any(score is not None for score in roc_auc_scores) else None\n",
    "    std_roc_auc = np.std([score for score in roc_auc_scores if score is not None]) if any(score is not None for score in roc_auc_scores) else None\n",
    "    mean_time = np.mean(computation_times)\n",
    "    std_time = np.std(computation_times)\n",
    "    \n",
    "    # Store results in a matrix format\n",
    "    results[name] = [\n",
    "        [\"Accuracy\", mean_accuracy, std_accuracy],\n",
    "        [\"Precision\", mean_precision, std_precision],\n",
    "        [\"Recall\", mean_recall, std_recall],\n",
    "        [\"F1 Score\", mean_f1, std_f1],\n",
    "        [\"ROC AUC\", mean_roc_auc, std_roc_auc],\n",
    "        [\"Computation Time (s)\", mean_time, std_time]\n",
    "    ]\n",
    "    \n",
    "    # Log results in a matrix format\n",
    "    logging.info(f\"Results for {name}:\")\n",
    "    for metric in results[name]:\n",
    "        logging.info(f\"{metric[0]}: {metric[1]:.3f} ± {metric[2]:.3f}\")\n",
    "    logging.info(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122b7ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xg16060\\Miniconda3\\envs\\survey_paper\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\xg16060\\AppData\\Local\\Temp\\1\\ipykernel_14504\\905786606.py:58: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  ('MLP', KerasClassifier(build_fn=lambda: create_network(number_of_features), epochs=100, batch_size=100, verbose=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "[[7126  168]\n",
      " [ 637  307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.918     0.977     0.947      7294\n",
      "           1      0.646     0.325     0.433       944\n",
      "\n",
      "    accuracy                          0.902      8238\n",
      "   macro avg      0.782     0.651     0.690      8238\n",
      "weighted avg      0.887     0.902     0.888      8238\n",
      "\n",
      "ROC AUC Score: 0.886\n",
      "Computation Time: 0.032 seconds\n",
      "\n",
      "Classifier: DT\n",
      "[[7106  188]\n",
      " [ 618  326]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.920     0.974     0.946      7294\n",
      "           1      0.634     0.345     0.447       944\n",
      "\n",
      "    accuracy                          0.902      8238\n",
      "   macro avg      0.777     0.660     0.697      8238\n",
      "weighted avg      0.887     0.902     0.889      8238\n",
      "\n",
      "ROC AUC Score: 0.839\n",
      "Computation Time: 0.027 seconds\n",
      "\n",
      "Classifier: RF\n",
      "[[7253   41]\n",
      " [ 777  167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.903     0.994     0.947      7294\n",
      "           1      0.803     0.177     0.290       944\n",
      "\n",
      "    accuracy                          0.901      8238\n",
      "   macro avg      0.853     0.586     0.618      8238\n",
      "weighted avg      0.892     0.901     0.871      8238\n",
      "\n",
      "ROC AUC Score: 0.884\n",
      "Computation Time: 1.692 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "[[7007  287]\n",
      " [ 636  308]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.917     0.961     0.938      7294\n",
      "           1      0.518     0.326     0.400       944\n",
      "\n",
      "    accuracy                          0.888      8238\n",
      "   macro avg      0.717     0.643     0.669      8238\n",
      "weighted avg      0.871     0.888     0.877      8238\n",
      "\n",
      "ROC AUC Score: 0.761\n",
      "Computation Time: 2.734 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "[[7062  232]\n",
      " [ 564  380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.926     0.968     0.947      7294\n",
      "           1      0.621     0.403     0.488       944\n",
      "\n",
      "    accuracy                          0.903      8238\n",
      "   macro avg      0.773     0.685     0.718      8238\n",
      "weighted avg      0.891     0.903     0.894      8238\n",
      "\n",
      "ROC AUC Score: 0.901\n",
      "Computation Time: 1.479 seconds\n",
      "\n",
      "Classifier: SVM\n",
      "[[7156  138]\n",
      " [ 670  274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.914     0.981     0.947      7294\n",
      "           1      0.665     0.290     0.404       944\n",
      "\n",
      "    accuracy                          0.902      8238\n",
      "   macro avg      0.790     0.636     0.675      8238\n",
      "weighted avg      0.886     0.902     0.884      8238\n",
      "\n",
      "ROC AUC Score: 0.836\n",
      "Computation Time: 68.372 seconds\n",
      "\n",
      "258/258 [==============================] - 0s 654us/step\n",
      "258/258 [==============================] - 0s 626us/step\n",
      "Classifier: MLP\n",
      "[[6997  297]\n",
      " [ 551  393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.927     0.959     0.943      7294\n",
      "           1      0.570     0.416     0.481       944\n",
      "\n",
      "    accuracy                          0.897      8238\n",
      "   macro avg      0.748     0.688     0.712      8238\n",
      "weighted avg      0.886     0.897     0.890      8238\n",
      "\n",
      "ROC AUC Score: 0.892\n",
      "Computation Time: 27.426 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "data_path_out = config_cat_embedding.paths['data_output']\n",
    "bank_data = pd.read_csv(data_path + 'bank-additional-full.csv', sep=';')\n",
    "\n",
    "df_bank, cat_cols = bank_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "target = df_bank.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=1500)\n",
    "\n",
    "# One-hot encoding\n",
    "import category_encoders as ce\n",
    "hash_encoder=ce.HashingEncoder(cols=cat_cols,n_components=9)\n",
    "X_train_ohe = hash_encoder.fit_transform(X_train)\n",
    "X_test_ohe = hash_encoder.transform(X_test)  # Use transform() instead of fit_transform()\n",
    "\n",
    "# Standard scaling\n",
    "stc = StandardScaler()\n",
    "X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "X_test_scaled = stc.transform(X_test_ohe)\n",
    "\n",
    "number_of_features = X_train_scaled.shape[1]  # Number of features in the input data\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss', use_label_encoder=False)),\n",
    "    ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(build_fn=lambda: create_network(number_of_features), epochs=100, batch_size=100, verbose=0))\n",
    "]\n",
    "\n",
    "# Train and evaluate the models\n",
    "for name, model in models:\n",
    "    start_time = time.time()  # Start time\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_prob = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    end_time = time.time()  # End time\n",
    "    computation_time = end_time - start_time  # Computation time\n",
    "    \n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, digits=3))  # Set digits to 3 for three decimal places\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_prob[:, 1]):.3f}\")\n",
    "    print(f\"Computation Time: {computation_time:.3f} seconds\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
