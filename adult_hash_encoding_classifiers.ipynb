{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf95b60-0d6a-47ca-ac4c-7824dfafddcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "Accuracy: 0.800 (95% CI: 0.797 - 0.803)\n",
      "Precision: 0.667 (95% CI: 0.656 - 0.677)\n",
      "Recall: 0.386 (95% CI: 0.375 - 0.397)\n",
      "F1 Score: 0.489 (95% CI: 0.479 - 0.498)\n",
      "ROC AUC: 0.845 (95% CI: 0.841 - 0.849)\n",
      "Total Computation Time: 25.346 seconds\n",
      "\n",
      "Classifier: DT\n",
      "Accuracy: 0.798 (95% CI: 0.795 - 0.800)\n",
      "Precision: 0.982 (95% CI: 0.977 - 0.986)\n",
      "Recall: 0.187 (95% CI: 0.178 - 0.197)\n",
      "F1 Score: 0.314 (95% CI: 0.301 - 0.327)\n",
      "ROC AUC: 0.809 (95% CI: 0.805 - 0.813)\n",
      "Total Computation Time: 27.934 seconds\n",
      "\n",
      "Classifier: RF\n",
      "Accuracy: 0.815 (95% CI: 0.812 - 0.818)\n",
      "Precision: 0.954 (95% CI: 0.948 - 0.960)\n",
      "Recall: 0.266 (95% CI: 0.256 - 0.276)\n",
      "F1 Score: 0.416 (95% CI: 0.404 - 0.428)\n",
      "ROC AUC: 0.872 (95% CI: 0.868 - 0.877)\n",
      "Total Computation Time: 84.038 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "Accuracy: 0.790 (95% CI: 0.787 - 0.793)\n",
      "Precision: 0.587 (95% CI: 0.581 - 0.593)\n",
      "Recall: 0.514 (95% CI: 0.503 - 0.525)\n",
      "F1 Score: 0.548 (95% CI: 0.540 - 0.556)\n",
      "ROC AUC: 0.782 (95% CI: 0.777 - 0.787)\n",
      "Total Computation Time: 55.068 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "Accuracy: 0.843 (95% CI: 0.839 - 0.846)\n",
      "Precision: 0.753 (95% CI: 0.745 - 0.761)\n",
      "Recall: 0.544 (95% CI: 0.533 - 0.555)\n",
      "F1 Score: 0.631 (95% CI: 0.622 - 0.641)\n",
      "ROC AUC: 0.901 (95% CI: 0.898 - 0.904)\n",
      "Total Computation Time: 30.575 seconds\n",
      "\n",
      "Classifier: MLP\n",
      "Accuracy: 0.823 (95% CI: 0.820 - 0.827)\n",
      "Precision: 0.696 (95% CI: 0.683 - 0.710)\n",
      "Recall: 0.512 (95% CI: 0.491 - 0.533)\n",
      "F1 Score: 0.589 (95% CI: 0.576 - 0.601)\n",
      "ROC AUC: 0.876 (95% CI: 0.872 - 0.880)\n",
      "Total Computation Time: 973.271 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add confidence interval\n",
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "from scipy import stats\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load and preprocess data\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "bank_data = pd.read_csv(data_path+'adult.csv', sep=',')\n",
    "\n",
    "df_bank, cat_cols = adult_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "y = df_bank.y\n",
    "\n",
    "# Convert target variable to numeric if necessary\n",
    "# Assuming 'y' contains 'yes'/'no', map them to 1/0\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "# We will determine the number_of_features inside the cross-validation loop after preprocessing\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss', random_state=seed)),\n",
    "    # ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(\n",
    "        model=create_network,\n",
    "        epochs=100, batch_size=100, verbose=0, random_state=seed))\n",
    "]\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)\n",
    "\n",
    "# Function to calculate confidence intervals\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, m - h, m + h\n",
    "\n",
    "# Loop over models\n",
    "for name, model in models:\n",
    "    print(f\"Classifier: {name}\")\n",
    "    # Lists to store metrics for each fold\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    roc_aucs = []\n",
    "    \n",
    "    # Start the timer before cross-validation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Preprocess data within the fold\n",
    "        # Hashing encoding\n",
    "        import category_encoders as ce\n",
    "        n_components = 9  \n",
    "        hashing_encoder = ce.HashingEncoder(cols=cat_cols, n_components=n_components, return_df=True)\n",
    "        X_train_hash = hashing_encoder.fit_transform(X_train_fold, y_train_fold)\n",
    "        X_test_hash = hashing_encoder.transform(X_test_fold)\n",
    "        \n",
    "        # Standard scaling\n",
    "        stc = StandardScaler()\n",
    "        X_train_scaled = stc.fit_transform(X_train_hash)\n",
    "        X_test_scaled = stc.transform(X_test_hash)\n",
    "        \n",
    "        # Update number_of_features for MLP\n",
    "        number_of_features = X_train_scaled.shape[1]\n",
    "        if name == 'MLP':\n",
    "            # Update the model with the correct number of features\n",
    "            model.set_params(model__number_of_features=number_of_features)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train_fold)\n",
    "        # Predict on the test fold\n",
    "        y_pred_fold = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Get prediction probabilities for ROC AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_prob_fold = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            print(\"no probability\")\n",
    "            # For classifiers without predict_proba, use decision_function\n",
    "            y_pred_prob_fold = model.decision_function(X_test_scaled)\n",
    "            # Normalize the decision function output to [0,1] range\n",
    "            y_pred_prob_fold = (y_pred_prob_fold - y_pred_prob_fold.min()) / (y_pred_prob_fold.max() - y_pred_prob_fold.min())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracies.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "        precisions.append(precision_score(y_test_fold, y_pred_fold, zero_division=0))\n",
    "        recalls.append(recall_score(y_test_fold, y_pred_fold))\n",
    "        f1s.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        roc_aucs.append(roc_auc_score(y_test_fold, y_pred_prob_fold))\n",
    "        \n",
    "        # print(f\"Fold {fold} completed.\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Stop the timer after cross-validation\n",
    "    end_time = time.time()\n",
    "    total_computation_time = end_time - start_time  # Total time for the model\n",
    "    \n",
    "    # Calculate mean and confidence intervals\n",
    "    acc_mean, acc_ci_lower, acc_ci_upper = confidence_interval(accuracies)\n",
    "    prec_mean, prec_ci_lower, prec_ci_upper = confidence_interval(precisions)\n",
    "    rec_mean, rec_ci_lower, rec_ci_upper = confidence_interval(recalls)\n",
    "    f1_mean, f1_ci_lower, f1_ci_upper = confidence_interval(f1s)\n",
    "    roc_mean, roc_ci_lower, roc_ci_upper = confidence_interval(roc_aucs)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {acc_mean:.3f} (95% CI: {acc_ci_lower:.3f} - {acc_ci_upper:.3f})\")\n",
    "    print(f\"Precision: {prec_mean:.3f} (95% CI: {prec_ci_lower:.3f} - {prec_ci_upper:.3f})\")\n",
    "    print(f\"Recall: {rec_mean:.3f} (95% CI: {rec_ci_lower:.3f} - {rec_ci_upper:.3f})\")\n",
    "    print(f\"F1 Score: {f1_mean:.3f} (95% CI: {f1_ci_lower:.3f} - {f1_ci_upper:.3f})\")\n",
    "    print(f\"ROC AUC: {roc_mean:.3f} (95% CI: {roc_ci_lower:.3f} - {roc_ci_upper:.3f})\")\n",
    "    print(f\"Total Computation Time: {total_computation_time:.3f} seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122b7ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "data_path_out = config_cat_embedding.paths['data_output']\n",
    "bank_data = pd.read_csv(data_path+'adult.csv', sep=',')\n",
    "\n",
    "df_bank, cat_cols = adult_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "target = df_bank.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=1500)\n",
    "\n",
    "# One-hot encoding\n",
    "import category_encoders as ce\n",
    "hash_encoder=ce.HashingEncoder(cols=cat_cols,n_components=9)\n",
    "X_train_ohe = hash_encoder.fit_transform(X_train)\n",
    "X_test_ohe = hash_encoder.transform(X_test)  # Use transform() instead of fit_transform()\n",
    "\n",
    "# Standard scaling\n",
    "stc = StandardScaler()\n",
    "X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "X_test_scaled = stc.transform(X_test_ohe)\n",
    "\n",
    "number_of_features = X_train_scaled.shape[1]  # Number of features in the input data\n",
    "\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss', use_label_encoder=False)),\n",
    "    ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(build_fn=lambda: create_network(number_of_features), epochs=100, batch_size=100, verbose=0))\n",
    "]\n",
    "\n",
    "# Train and evaluate the models\n",
    "for name, model in models:\n",
    "    start_time = time.time()  # Start time\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_prob = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    end_time = time.time()  # End time\n",
    "    computation_time = end_time - start_time  # Computation time\n",
    "    \n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, digits=3))  # Set digits to 3 for three decimal places\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_prob[:, 1]):.3f}\")\n",
    "    print(f\"Computation Time: {computation_time:.3f} seconds\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2add287f-0b4b-43d5-8b0d-18b4c1b23453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LR\n",
      "Mean Accuracy: 0.800 ± 0.003\n",
      "Mean Precision: 0.667 ± 0.006\n",
      "Mean Recall: 0.392 ± 0.016\n",
      "Mean F1 Score: 0.494 ± 0.013\n",
      "Mean ROC AUC: 0.847 ± 0.004\n",
      "Mean Computation Time: 0.031 ± 0.002 seconds\n",
      "\n",
      "Classifier: DT\n",
      "Mean Accuracy: 0.797 ± 0.001\n",
      "Mean Precision: 0.980 ± 0.007\n",
      "Mean Recall: 0.188 ± 0.005\n",
      "Mean F1 Score: 0.315 ± 0.007\n",
      "Mean ROC AUC: 0.811 ± 0.005\n",
      "Mean Computation Time: 0.046 ± 0.005 seconds\n",
      "\n",
      "Classifier: RF\n",
      "Mean Accuracy: 0.815 ± 0.003\n",
      "Mean Precision: 0.954 ± 0.014\n",
      "Mean Recall: 0.267 ± 0.010\n",
      "Mean F1 Score: 0.417 ± 0.014\n",
      "Mean ROC AUC: 0.874 ± 0.005\n",
      "Mean Computation Time: 2.495 ± 0.044 seconds\n",
      "\n",
      "Classifier: KNN\n",
      "Mean Accuracy: 0.790 ± 0.003\n",
      "Mean Precision: 0.587 ± 0.009\n",
      "Mean Recall: 0.515 ± 0.004\n",
      "Mean F1 Score: 0.549 ± 0.005\n",
      "Mean ROC AUC: 0.783 ± 0.007\n",
      "Mean Computation Time: 7.481 ± 0.726 seconds\n",
      "\n",
      "Classifier: XGB\n",
      "Mean Accuracy: 0.840 ± 0.006\n",
      "Mean Precision: 0.740 ± 0.021\n",
      "Mean Recall: 0.549 ± 0.011\n",
      "Mean F1 Score: 0.630 ± 0.012\n",
      "Mean ROC AUC: 0.898 ± 0.004\n",
      "Mean Computation Time: 0.280 ± 0.014 seconds\n",
      "\n",
      "Classifier: SVM\n",
      "Mean Accuracy: 0.825 ± 0.006\n",
      "Mean Precision: 0.759 ± 0.020\n",
      "Mean Recall: 0.430 ± 0.012\n",
      "Mean F1 Score: 0.549 ± 0.015\n",
      "Mean ROC AUC: 0.853 ± 0.006\n",
      "Mean Computation Time: 924.261 ± 65.973 seconds\n",
      "\n",
      "Classifier: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\P70071469\\AppData\\Local\\anaconda3\\envs\\SLR\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.818 ± 0.003\n",
      "Mean Precision: 0.669 ± 0.016\n",
      "Mean Recall: 0.532 ± 0.041\n",
      "Mean F1 Score: 0.591 ± 0.020\n",
      "Mean ROC AUC: 0.872 ± 0.004\n",
      "Mean Computation Time: 47.684 ± 3.187 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import config_cat_embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data_prep import bank_data_prep, adult_data_prep\n",
    "from embedding_helper import create_network\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "data_path = config_cat_embedding.paths['data']\n",
    "data_path_out = config_cat_embedding.paths['data_output']\n",
    "bank_data = pd.read_csv(data_path+'adult.csv', sep=',')\n",
    "\n",
    "df_bank, cat_cols = adult_data_prep(bank_data)\n",
    "\n",
    "X = df_bank.iloc[:, :-1]\n",
    "target = df_bank.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=1500)\n",
    "\n",
    "# One-hot encoding\n",
    "import category_encoders as ce\n",
    "hash_encoder=ce.HashingEncoder(cols=cat_cols,n_components=9)\n",
    "X_train_ohe = hash_encoder.fit_transform(X_train)\n",
    "X_test_ohe = hash_encoder.transform(X_test)  # Use transform() instead of fit_transform()\n",
    "\n",
    "# Standard scaling\n",
    "stc = StandardScaler()\n",
    "X_train_scaled = stc.fit_transform(X_train_ohe)\n",
    "X_test_scaled = stc.transform(X_test_ohe)\n",
    "# Define the classifiers\n",
    "seed = 42\n",
    "number_of_features = X_train_scaled.shape[1]  # Number of features in the input data\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='lbfgs', random_state=seed, max_iter=1000)),\n",
    "    ('DT', DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed)),\n",
    "    ('RF', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=seed, min_samples_leaf=3)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('XGB', XGBClassifier(eval_metric='logloss')),\n",
    "    ('SVM', SVC(gamma='scale', random_state=seed, probability=True)),\n",
    "    ('MLP', KerasClassifier(build_fn=create_network, number_of_features=number_of_features, epochs=100, batch_size=100, verbose=0))\n",
    "]\n",
    "\n",
    "# Define number of runs for cross-validation\n",
    "n_runs = 5\n",
    "kf = StratifiedKFold(n_splits=n_runs, shuffle=True, random_state=seed)\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Loop over the models\n",
    "for name, model in models:\n",
    "    print(f\"Classifier: {name}\")\n",
    "    \n",
    "    # Lists to store metrics for each fold\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    roc_auc_scores = []\n",
    "    computation_times = []\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for train_idx, test_idx in kf.split(X_train_scaled, y_train):\n",
    "        # Clone the model to ensure fresh training for each fold\n",
    "        clf = clone(model)\n",
    "        \n",
    "        X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "        \n",
    "        start_time = time.time()  # Start time\n",
    "        \n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = clf.predict(X_test_fold)\n",
    "        y_pred_prob = clf.predict_proba(X_test_fold)[:, 1]  # Probabilities for ROC AUC\n",
    "        \n",
    "        end_time = time.time()  # End time\n",
    "        computation_time = end_time - start_time  # Computation time\n",
    "        \n",
    "        # Append metrics for this fold\n",
    "        accuracy_scores.append(accuracy_score(y_test_fold, y_pred))\n",
    "        precision_scores.append(precision_score(y_test_fold, y_pred))\n",
    "        recall_scores.append(recall_score(y_test_fold, y_pred))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred))\n",
    "        roc_auc_scores.append(roc_auc_score(y_test_fold, y_pred_prob))\n",
    "        computation_times.append(computation_time)\n",
    "    \n",
    "    # Compute mean and standard deviation of all metrics\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    std_accuracy = np.std(accuracy_scores)\n",
    "    \n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    std_precision = np.std(precision_scores)\n",
    "    \n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    std_recall = np.std(recall_scores)\n",
    "    \n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    std_f1 = np.std(f1_scores)\n",
    "    \n",
    "    mean_roc_auc = np.mean(roc_auc_scores)\n",
    "    std_roc_auc = np.std(roc_auc_scores)\n",
    "    \n",
    "    mean_time = np.mean(computation_times)\n",
    "    std_time = np.std(computation_times)\n",
    "    \n",
    "    # Store results for the current model\n",
    "    results[name] = {\n",
    "        \"Mean Accuracy\": mean_accuracy, \"STD Accuracy\": std_accuracy,\n",
    "        \"Mean Precision\": mean_precision, \"STD Precision\": std_precision,\n",
    "        \"Mean Recall\": mean_recall, \"STD Recall\": std_recall,\n",
    "        \"Mean F1 Score\": mean_f1, \"STD F1 Score\": std_f1,\n",
    "        \"Mean ROC AUC\": mean_roc_auc, \"STD ROC AUC\": std_roc_auc,\n",
    "        \"Mean Time\": mean_time, \"STD Time\": std_time\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.3f} ± {std_accuracy:.3f}\")\n",
    "    print(f\"Mean Precision: {mean_precision:.3f} ± {std_precision:.3f}\")\n",
    "    print(f\"Mean Recall: {mean_recall:.3f} ± {std_recall:.3f}\")\n",
    "    print(f\"Mean F1 Score: {mean_f1:.3f} ± {std_f1:.3f}\")\n",
    "    print(f\"Mean ROC AUC: {mean_roc_auc:.3f} ± {std_roc_auc:.3f}\")\n",
    "    print(f\"Mean Computation Time: {mean_time:.3f} ± {std_time:.3f} seconds\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
